<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hello World! Hello GLSL!</title>
<link rel="stylesheet" href="style.css">

</head>
<body>
<p>Hello World! Hello GLSL!</p>
<canvas>Your browser does not seem to support HTML canvas.</canvas>
<button id="play" class="audio-btn">Start</button>
<script type="x-shader/x-vertex" id="vertex-shader">
  attribute vec2 a_position;
  varying vec2 v_uv;
  
  void main() {
    v_uv = a_position * 0.5 + 0.5; // Convert from -1..1 to 0..1
    gl_Position = vec4(a_position, 0.0, 1.0);
  }
</script>
<script type="x-shader/x-fragment" id="fragment-shader">
  precision mediump float;
  
  uniform vec2 u_resolution;
  uniform float u_time;
  uniform float u_beatTime;
  uniform float u_beatPhase;
  uniform int u_audioStarted;
  uniform float u_transitionProgress;
  uniform float u_speechPhase;
  uniform int u_isSpeaking;
  
  varying vec2 v_uv;
  
  // Mandelbrot computation function
  float mandelbrot(vec2 uv, vec2 center, float zoom, float rotation, int maxIter) {
    vec2 c = (uv - 0.5) * 2.0;
    c.x *= u_resolution.x / u_resolution.y;
    
    // Apply rotation
    float cosR = cos(rotation);
    float sinR = sin(rotation);
    c = vec2(c.x * cosR - c.y * sinR, c.x * sinR + c.y * cosR);
    
    // Apply zoom and center
    c = c / zoom + center;
    
    vec2 z = vec2(0.0);
    int iterations = 0;
    
    for (int i = 0; i < 256; i++) {
      if (i >= maxIter) break;
      
      float x = (z.x * z.x - z.y * z.y) + c.x;
      float y = (z.x * z.y * 2.0) + c.y;
      z = vec2(x, y);
      
      if (dot(z, z) > 4.0) {
        iterations = i;
        break;
      }
    }
    
    if (iterations == maxIter) {
      return 0.0; // Return 0.0 for inside the set (becomes white after inversion)
    }
    
    return float(iterations) / float(maxIter);
  }
  
  // Simple noise function
  float noise(vec2 p) {
    return fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453);
  }
  
  // Check if point is inside triangle using barycentric coordinates
  float pointInTriangle(vec2 p, vec2 a, vec2 b, vec2 c) {
    vec2 v0 = c - a;
    vec2 v1 = b - a;
    vec2 v2 = p - a;
    
    float dot00 = dot(v0, v0);
    float dot01 = dot(v0, v1);
    float dot02 = dot(v0, v2);
    float dot11 = dot(v1, v1);
    float dot12 = dot(v1, v2);
    
    float invDenom = 1.0 / (dot00 * dot11 - dot01 * dot01);
    float u = (dot11 * dot02 - dot01 * dot12) * invDenom;
    float v = (dot00 * dot12 - dot01 * dot02) * invDenom;
    
    return (u >= 0.0) && (v >= 0.0) && (u + v <= 1.0) ? 1.0 : 0.0;
  }
  
  // Check if point is inside hexagon
  float pointInHexagon(vec2 p, vec2 center, float radius) {
    vec2 pos = p - center;
    float angle = atan(pos.y, pos.x);
    float dist = length(pos);
    
    // Hexagon has 6 sides, so we check distance to each edge
    float angleStep = 3.14159 / 3.0; // 60 degrees in radians
    float normalizedAngle = mod(angle + angleStep * 0.5, angleStep) - angleStep * 0.5;
    float edgeDist = radius * cos(angleStep * 0.5) / cos(normalizedAngle);
    
    return dist <= edgeDist ? 1.0 : 0.0;
  }
  
  // Render shape that morphs between triangle and hexagon
  float renderMorphingShape(vec2 uv) {
    // Animation cycle: 30 seconds triangle -> hexagon, 30 seconds hexagon -> triangle
    float cycleTime = 30.0;
    float fullCycle = cycleTime * 2.0; // 60 seconds total
    float t = mod(u_time, fullCycle);
    float morphFactor;
    
    if (t < cycleTime) {
      // First 30 seconds: triangle (0) to hexagon (1)
      morphFactor = t / cycleTime;
    } else {
      // Next 30 seconds: hexagon (1) to triangle (0)
      float t2 = t - cycleTime;
      morphFactor = 1.0 - (t2 / cycleTime);
    }
    
    // Ultra-smooth interpolation using smootherstep (quintic easing)
    // This provides a much smoother transition than regular smoothstep
    float t_smooth = morphFactor;
    morphFactor = t_smooth * t_smooth * t_smooth * (t_smooth * (t_smooth * 6.0 - 15.0) + 10.0);
    
    // Triangle shape
    vec2 v0 = vec2(0.5, 0.9);   // Top center
    vec2 v1 = vec2(0.1, 0.1);   // Bottom left
    vec2 v2 = vec2(0.9, 0.1);   // Bottom right
    float triangleAlpha = pointInTriangle(uv, v0, v1, v2);
    
    // Hexagon shape (centered, scaled to fill screen)
    vec2 center = vec2(0.5, 0.5);
    float hexRadius = 0.4;
    float hexAlpha = pointInHexagon(uv, center, hexRadius);
    
    // Morph between triangle and hexagon with smooth transition
    return mix(triangleAlpha, hexAlpha, morphFactor);
  }
  
  // Screen curvature/distortion with hallucinogenic warping
  vec2 crtDistort(vec2 uv) {
    uv = (uv - 0.5) * 2.0;
    
    // Radial distortion with beat sync, speech sync, and smooth transition
    float dist = length(uv);
    float beatDistortion = 1.0 + 0.15 * (uv.x * uv.x + uv.y * uv.y);
    beatDistortion += u_beatPhase * 0.1 * u_transitionProgress; // Pulse on beat, scaled by transition
    beatDistortion += u_speechPhase * 0.2 * u_transitionProgress; // Pulse on speech, scaled by transition
    uv *= beatDistortion;
    
    // Psychedelic wave distortion (slowed down) with beat sync, speech sync, and transition
    float waveIntensity = 0.1 * u_transitionProgress;
    waveIntensity += u_beatPhase * 0.05 * u_transitionProgress;
    waveIntensity += u_speechPhase * 0.15 * u_transitionProgress; // Stronger waves during speech
    float waveX = sin(uv.y * 3.0 + u_time * 0.5 + u_speechPhase * 2.0) * waveIntensity;
    float waveY = cos(uv.x * 3.0 + u_time * 0.375 + u_speechPhase * 2.0) * waveIntensity;
    uv += vec2(waveX, waveY);
    
    // Spiral distortion (slowed down) with beat sync, speech sync, and transition
    float angle = atan(uv.y, uv.x) + dist * 2.0;
    angle += u_time * 0.25 * u_transitionProgress;
    angle += u_speechPhase * 1.5 * u_transitionProgress; // Rotate more during speech
    float spiral = sin(angle * 3.0) * (0.05 + u_beatPhase * 0.03 + u_speechPhase * 0.08) * u_transitionProgress;
    uv += vec2(cos(angle), sin(angle)) * spiral;
    
    return (uv + 1.0) * 0.5;
  }
  
  void main() {
    // Apply CRT screen distortion
    vec2 distortedUV = crtDistort(v_uv);
    
    // Enhanced chromatic aberration with psychedelic separation, beat sync, and speech sync (smooth transition)
    float aberration = 0.008 + (0.005 * sin(u_time * 0.75) + u_beatPhase * 0.01 + u_speechPhase * 0.015) * u_transitionProgress;
    vec2 offsetR = vec2(
      aberration * sin(u_time * 1.0 + distortedUV.y * 10.0 + u_beatPhase * 2.0 + u_speechPhase * 3.0) * u_transitionProgress,
      aberration * 0.5 * cos(u_time * 0.875 + distortedUV.x * 8.0 + u_speechPhase * 2.5) * u_transitionProgress
    );
    vec2 offsetG = vec2(0.0, 0.0);
    vec2 offsetB = vec2(
      -aberration * sin(u_time * 1.0 + distortedUV.y * 10.0 + u_beatPhase * 2.0 + u_speechPhase * 3.0) * u_transitionProgress,
      -aberration * 0.5 * cos(u_time * 0.875 + distortedUV.x * 8.0 + u_speechPhase * 2.5) * u_transitionProgress
    );
    
    // Sample fractal with different UV offsets for RGB channels
    vec2 uvR = distortedUV + offsetR;
    vec2 uvG = distortedUV + offsetG;
    vec2 uvB = distortedUV + offsetB;
    
    // Compute fractal for each channel
    vec3 finalColor = vec3(0.0);
    
    // All fractals use the same static position before audio starts
    vec2 staticCenter = vec2(-0.5, 0.0);
    float staticZoom = 1.0;
    float staticRot = 0.0;
    
    // Smooth transition interpolation
    float transition = u_transitionProgress;
    
    // Layer 1: Red/Orange fractal
    float t1 = u_time * 0.15 * transition;
    vec2 targetCenter1 = vec2(-0.5 + 0.2 * sin(t1), 0.0 + 0.2 * cos(t1 * 0.7));
    float targetZoom1 = 1.0 + 0.5 * sin(t1 * 0.5);
    float targetRot1 = t1 * 0.2;
    vec2 center1 = mix(staticCenter, targetCenter1, transition);
    float zoom1 = mix(staticZoom, targetZoom1, transition);
    float rot1 = mix(staticRot, targetRot1, transition);
    
    float m1R = mandelbrot(uvR, center1, zoom1, rot1, 80);
    float m1G = mandelbrot(uvG, center1, zoom1, rot1, 80);
    float m1B = mandelbrot(uvB, center1, zoom1, rot1, 80);
    
    vec3 whiteColor1 = vec3(m1R, m1G, m1B);
    vec3 animatedColor1 = vec3(
      0.8 + 0.2 * cos(m1R * 20.0 + t1),
      0.3 + 0.2 * sin(m1G * 15.0),
      0.1
    ) * vec3(m1R, m1G, m1B) * 0.6;
    vec3 color1 = mix(whiteColor1, animatedColor1, transition);
    finalColor += color1;
    
    // Layer 2: Cyan/Blue fractal
    float t2 = u_time * 0.2 * transition;
    vec2 targetCenter2 = vec2(-0.75 + 0.15 * cos(t2 * 0.8), 0.1 + 0.15 * sin(t2));
    float targetZoom2 = 1.2 + 0.3 * cos(t2 * 0.6);
    float targetRot2 = -t2 * 0.15;
    vec2 center2 = mix(staticCenter, targetCenter2, transition);
    float zoom2 = mix(staticZoom, targetZoom2, transition);
    float rot2 = mix(staticRot, targetRot2, transition);
    
    float m2R = mandelbrot(uvR, center2, zoom2, rot2, 100);
    float m2G = mandelbrot(uvG, center2, zoom2, rot2, 100);
    float m2B = mandelbrot(uvB, center2, zoom2, rot2, 100);
    
    vec3 whiteColor2 = vec3(m2R, m2G, m2B);
    vec3 animatedColor2 = vec3(
      0.1,
      0.5 + 0.3 * cos(m2G * 18.0 + t2 * 2.0),
      0.9 + 0.1 * sin(m2B * 12.0)
    ) * vec3(m2R, m2G, m2B) * 0.5;
    vec3 color2 = mix(whiteColor2, animatedColor2, transition);
    finalColor += color2;
    
    // Layer 3: Green/Magenta fractal
    float t3 = u_time * 0.25 * transition;
    vec2 targetCenter3 = vec2(-0.2 + 0.1 * sin(t3 * 1.2), 0.8 + 0.1 * cos(t3 * 0.9));
    float targetZoom3 = 0.8 + 0.4 * sin(t3 * 0.7);
    float targetRot3 = t3 * 0.25;
    vec2 center3 = mix(staticCenter, targetCenter3, transition);
    float zoom3 = mix(staticZoom, targetZoom3, transition);
    float rot3 = mix(staticRot, targetRot3, transition);
    
    float m3R = mandelbrot(uvR, center3, zoom3, rot3, 90);
    float m3G = mandelbrot(uvG, center3, zoom3, rot3, 90);
    float m3B = mandelbrot(uvB, center3, zoom3, rot3, 90);
    
    vec3 whiteColor3 = vec3(m3R, m3G, m3B);
    vec3 animatedColor3 = vec3(
      0.2 + 0.3 * sin(m3R * 16.0),
      0.8 + 0.2 * cos(m3G * 14.0 + t3),
      0.4 + 0.3 * sin(m3B * 10.0)
    ) * vec3(m3R, m3G, m3B) * 0.4;
    vec3 color3 = mix(whiteColor3, animatedColor3, transition);
    finalColor += color3;
    
    // Layer 4: Purple/Yellow fractal
    float t4 = u_time * 0.125 * transition;
    vec2 targetCenter4 = vec2(0.0 + 0.12 * cos(t4 * 0.5), -0.5 + 0.12 * sin(t4 * 0.6));
    float targetZoom4 = 1.1 + 0.2 * cos(t4 * 0.4);
    float targetRot4 = -t4 * 0.1;
    vec2 center4 = mix(staticCenter, targetCenter4, transition);
    float zoom4 = mix(staticZoom, targetZoom4, transition);
    float rot4 = mix(staticRot, targetRot4, transition);
    
    float m4R = mandelbrot(uvR, center4, zoom4, rot4, 85);
    float m4G = mandelbrot(uvG, center4, zoom4, rot4, 85);
    float m4B = mandelbrot(uvB, center4, zoom4, rot4, 85);
    
    vec3 whiteColor4 = vec3(m4R, m4G, m4B);
    vec3 animatedColor4 = vec3(
      0.6 + 0.2 * cos(m4R * 22.0),
      0.3 + 0.2 * sin(m4G * 19.0),
      0.7 + 0.2 * cos(m4B * 17.0 + t4)
    ) * vec3(m4R, m4G, m4B) * 0.35;
    vec3 color4 = mix(whiteColor4, animatedColor4, transition);
    finalColor += color4;
    
    // Enhanced contrast and color enhancement with beat sync and smooth transition
    float contrastBoost = 0.75 - u_beatPhase * 0.1 * u_transitionProgress; // More contrast on beat, scaled by transition
    finalColor = pow(finalColor, vec3(contrastBoost));
    
    // Intense color cycling/shifting (slowed down) with beat sync, speech sync, and transition
    float colorShift = (u_time * 0.125 + u_beatPhase * 0.5 + u_speechPhase * 1.0) * u_transitionProgress; // Shift colors on beat and speech, scaled by transition
    vec3 colorShiftVec = vec3(
      sin(colorShift),
      sin(colorShift + 2.094), // 120 degrees
      sin(colorShift + 4.189)  // 240 degrees
    ) * 0.3 + 0.7;
    // Blend between no color shift and full color shift
    finalColor = mix(finalColor, finalColor * colorShiftVec, u_transitionProgress);
    
    // Beat-synced and speech-synced brightness pulse with transition
    finalColor *= (1.0 + u_beatPhase * 0.3 * u_transitionProgress + u_speechPhase * 0.4 * u_transitionProgress);
    
    // Increased saturation and contrast with transition
    float luminance = dot(finalColor, vec3(0.299, 0.587, 0.114));
    float saturation = mix(1.0, 1.8 + u_beatPhase * 0.4, u_transitionProgress); // Transition from 1.0 to animated saturation
    finalColor = mix(vec3(luminance), finalColor, saturation);
    
    // Contrast boost with beat sync and transition
    float contrast = mix(1.0, 1.5 + u_beatPhase * 0.3, u_transitionProgress);
    finalColor = (finalColor - 0.5) * contrast + 0.5;
    
    finalColor = clamp(finalColor, 0.0, 1.0);
    
    // CRT Effects
    vec2 screenUV = distortedUV;
    
    // Scanlines
    float scanline = sin(screenUV.y * u_resolution.y * 0.7) * 0.5 + 0.5;
    scanline = pow(scanline, 8.0);
    finalColor *= mix(0.95, 1.0, scanline);
    
    // Horizontal scanline flicker
    float flicker = 1.0;
    if (u_audioStarted > 0) {
      flicker = 0.98 + 0.02 * sin(u_time * 30.0);
    }
    finalColor *= flicker;
    
    // Vignette
    vec2 vignetteUV = (screenUV - 0.5) * 2.0;
    float vignette = 1.0 - dot(vignetteUV, vignetteUV) * 0.3;
    finalColor *= vignette;
    
    // Static noise
    float staticNoise = noise(vec2(screenUV * u_resolution + (u_audioStarted > 0 ? u_time * 10.0 : 0.0)));
    finalColor += (staticNoise - 0.5) * 0.02;
    
    // Intense screen warp/glitch with hallucinations (slowed down), speech sync, and transition
    float glitch = step(0.95 - u_speechPhase * 0.1, noise(vec2(u_time * 0.25 + u_speechPhase * 2.0, screenUV.y * 10.0))) * u_transitionProgress;
    float glitch2 = step(0.97 - u_speechPhase * 0.1, noise(vec2(u_time * 0.175 + u_speechPhase * 1.5, screenUV.x * 15.0))) * u_transitionProgress;
    
    // Color channel swapping with transition
    if (glitch > 0.5) {
      vec3 temp = finalColor;
      finalColor.r = temp.b;
      finalColor.b = temp.g;
      finalColor.g = temp.r;
    }
    
    // Intense color shifts during glitches with transition
    finalColor = mix(finalColor, finalColor * vec3(1.5, 0.6, 1.8), glitch * 0.5);
    finalColor = mix(finalColor, finalColor * vec3(0.7, 1.6, 0.9), glitch2 * 0.4);
    
    // Enhanced color bleed with time-based variation (slowed down), speech sync, and transition
    float bleedAmount = mix(0.2, 0.2 + 0.1 * sin(u_time * 0.5) + u_speechPhase * 0.15, u_transitionProgress);
    finalColor.r = mix(finalColor.r, finalColor.g, bleedAmount);
    finalColor.b = mix(finalColor.b, finalColor.g, bleedAmount);
    
    // Radial color gradients (kaleidoscope effect) - slowed down with transition
    vec2 center = screenUV - 0.5;
    float radial = length(center);
    float angle = atan(center.y, center.x) + u_time * 0.25 * u_transitionProgress;
    vec3 radialColor = vec3(
      0.5 + 0.5 * sin(angle * 2.0 + radial * 10.0),
      0.5 + 0.5 * sin(angle * 2.0 + radial * 10.0 + 2.094),
      0.5 + 0.5 * sin(angle * 2.0 + radial * 10.0 + 4.189)
    );
    finalColor = mix(finalColor, finalColor * radialColor, 0.15 * u_transitionProgress);
    
    // Transition effect: gradual fade-in of effects with a subtle pulse
    float transitionPulse = sin(u_transitionProgress * 3.14159) * 0.1 + 1.0; // Pulse during transition
    finalColor *= transitionPulse;
    
    // Final clamp
    finalColor = clamp(finalColor, 0.0, 1.0);
    
    // Check if we're in the background (inside the set - very dark areas)
    float intensity = dot(finalColor, vec3(0.299, 0.587, 0.114));
    if (intensity < 0.1) {
      // Pure black background (becomes white after inversion)
      finalColor = vec3(0.0);
    } else {
      // Invert colors for fractal areas (black becomes white)
      finalColor = 1.0 - finalColor;
    }
    
    // Render red shape (morphing triangle/hexagon) with 50% opacity
    float shapeAlpha = renderMorphingShape(v_uv);
    vec3 shapeColor = vec3(1.0, 0.0, 0.0); // Red
    finalColor = mix(finalColor, shapeColor, shapeAlpha * 0.5); // 50% opacity
    
    gl_FragColor = vec4(finalColor, 1.0);
  }
</script>
<script>
// Speech synthesis function - pitch counter
let pitchCounter = 0;
const pitchValues = [0, 1, 1.5, 2.0];

// Store voices globally for mobile compatibility
let availableVoices = [];
let voicesLoaded = false;

// Load voices (especially important for mobile)
function loadVoices() {
    availableVoices = speechSynthesis.getVoices();
    voicesLoaded = true;
}

// Initialize voices - mobile browsers need this
if (speechSynthesis.onvoiceschanged !== undefined) {
    speechSynthesis.onvoiceschanged = loadVoices;
}
// Load immediately if already available
loadVoices();

function sayIt() {
    // Ensure voices are loaded (critical for mobile)
    if (!voicesLoaded || availableVoices.length === 0) {
        availableVoices = speechSynthesis.getVoices();
        if (availableVoices.length > 0) {
            voicesLoaded = true;
        }
    }
    
    const text = "Mita vittua Timo";

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = "fi-FI";         // force Finnish
    utterance.rate = 0.8;               // natural speed
    // Cycle through pitch values: 0 -> 1 -> 1.5 -> 2.0
    utterance.pitch = pitchValues[pitchCounter % pitchValues.length];
    pitchCounter++;
    utterance.volume = 1;

    // Try to pick a Finnish voice if available
    if (availableVoices.length > 0) {
        const finnishVoice = availableVoices.find(v =>
            v.lang.toLowerCase().includes("fi")
        );
        if (finnishVoice) {
            utterance.voice = finnishVoice;
        }
    }

    // Track speech state (used by speech.js)
    utterance.onstart = () => {
        if (typeof isSpeaking !== 'undefined') {
            isSpeaking = true;
        }
        if (typeof speechStartTime !== 'undefined') {
            speechStartTime = Date.now();
        }
        if (typeof speechPhase !== 'undefined') {
            speechPhase = 1.0; // Start at full intensity
        }
    };

    utterance.onend = () => {
        if (typeof isSpeaking !== 'undefined') {
            isSpeaking = false;
        }
        if (typeof speechPhase !== 'undefined') {
            speechPhase = 0.0;
        }
    };

    // Error handling for mobile
    utterance.onerror = (event) => {
        console.log('Speech synthesis error:', event.error);
        if (typeof isSpeaking !== 'undefined') {
            isSpeaking = false;
        }
        if (typeof speechPhase !== 'undefined') {
            speechPhase = 0.0;
        }
    };

    // Cancel any ongoing speech before starting new one (important for mobile)
    if (speechSynthesis.speaking) {
        speechSynthesis.cancel();
    }
    
    speechSynthesis.speak(utterance);
}
</script>
<script src="speech.js"></script>
<script src="script.js"></script>
</body>
</html>